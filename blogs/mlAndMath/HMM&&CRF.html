<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>HMM and CRF | richard&#39;s blog</title>
    <meta name="generator" content="VuePress 1.5.4">
    <link rel="icon" href="/blogs/favicon.ico">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <link rel="preload" href="/blogs/assets/css/0.styles.1157b0c6.css" as="style"><link rel="preload" href="/blogs/assets/js/app.3f11a259.js" as="script"><link rel="preload" href="/blogs/assets/js/3.20f81737.js" as="script"><link rel="preload" href="/blogs/assets/js/1.0bcafa9d.js" as="script"><link rel="preload" href="/blogs/assets/js/36.88d814f7.js" as="script"><link rel="prefetch" href="/blogs/assets/js/10.7ca4ef6a.js"><link rel="prefetch" href="/blogs/assets/js/11.c8a61b59.js"><link rel="prefetch" href="/blogs/assets/js/12.5d40e87f.js"><link rel="prefetch" href="/blogs/assets/js/13.a32c27d2.js"><link rel="prefetch" href="/blogs/assets/js/14.8f9319d1.js"><link rel="prefetch" href="/blogs/assets/js/15.9e6a2cb7.js"><link rel="prefetch" href="/blogs/assets/js/16.751532c7.js"><link rel="prefetch" href="/blogs/assets/js/17.4ea0fb6a.js"><link rel="prefetch" href="/blogs/assets/js/18.4502d066.js"><link rel="prefetch" href="/blogs/assets/js/19.e52ca789.js"><link rel="prefetch" href="/blogs/assets/js/20.0346bf4f.js"><link rel="prefetch" href="/blogs/assets/js/21.acd487f8.js"><link rel="prefetch" href="/blogs/assets/js/22.560692a6.js"><link rel="prefetch" href="/blogs/assets/js/23.bbb61a77.js"><link rel="prefetch" href="/blogs/assets/js/24.7c693121.js"><link rel="prefetch" href="/blogs/assets/js/25.706d5405.js"><link rel="prefetch" href="/blogs/assets/js/26.d7166dd5.js"><link rel="prefetch" href="/blogs/assets/js/27.bd6c26bd.js"><link rel="prefetch" href="/blogs/assets/js/28.98a99b90.js"><link rel="prefetch" href="/blogs/assets/js/29.dd5e888c.js"><link rel="prefetch" href="/blogs/assets/js/30.5d575209.js"><link rel="prefetch" href="/blogs/assets/js/31.d6afaa08.js"><link rel="prefetch" href="/blogs/assets/js/32.18c7bcfe.js"><link rel="prefetch" href="/blogs/assets/js/33.0136b133.js"><link rel="prefetch" href="/blogs/assets/js/34.43bee147.js"><link rel="prefetch" href="/blogs/assets/js/35.2d6864ee.js"><link rel="prefetch" href="/blogs/assets/js/37.7a718561.js"><link rel="prefetch" href="/blogs/assets/js/38.b85440d8.js"><link rel="prefetch" href="/blogs/assets/js/39.24394710.js"><link rel="prefetch" href="/blogs/assets/js/4.f02b9190.js"><link rel="prefetch" href="/blogs/assets/js/40.72938072.js"><link rel="prefetch" href="/blogs/assets/js/41.c2111101.js"><link rel="prefetch" href="/blogs/assets/js/42.900b4b5a.js"><link rel="prefetch" href="/blogs/assets/js/43.b1b19eba.js"><link rel="prefetch" href="/blogs/assets/js/44.0b359d11.js"><link rel="prefetch" href="/blogs/assets/js/45.b58274f7.js"><link rel="prefetch" href="/blogs/assets/js/46.fca67968.js"><link rel="prefetch" href="/blogs/assets/js/47.cdfc3c26.js"><link rel="prefetch" href="/blogs/assets/js/48.58309296.js"><link rel="prefetch" href="/blogs/assets/js/49.6a602edf.js"><link rel="prefetch" href="/blogs/assets/js/5.a334d371.js"><link rel="prefetch" href="/blogs/assets/js/50.f383e87c.js"><link rel="prefetch" href="/blogs/assets/js/51.bd9877e7.js"><link rel="prefetch" href="/blogs/assets/js/52.3c82c076.js"><link rel="prefetch" href="/blogs/assets/js/53.29c221f4.js"><link rel="prefetch" href="/blogs/assets/js/54.e65c55b9.js"><link rel="prefetch" href="/blogs/assets/js/6.35e528d3.js"><link rel="prefetch" href="/blogs/assets/js/7.cac617fb.js"><link rel="prefetch" href="/blogs/assets/js/8.42a61663.js"><link rel="prefetch" href="/blogs/assets/js/9.851ca25f.js">
    <link rel="stylesheet" href="/blogs/assets/css/0.styles.1157b0c6.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-2d5f533b><div data-v-2d5f533b><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-2d5f533b data-v-2d5f533b><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-64685f0e data-v-2d5f533b data-v-2d5f533b><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>richard's blog</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>gouqi</span>
            
          <span data-v-64685f0e>2020 - </span>
          2023
        </a></span></div></div> <div class="hide" data-v-2d5f533b><header class="navbar" data-v-2d5f533b><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blogs/" class="home-link router-link-active"><img src="/blogs/logo.png" alt="richard's blog" class="logo"> <span class="site-name">richard's blog</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blogs/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blogs/categories/algorithm/" class="nav-link"><i class="iconfont undefined"></i>
  algorithm
</a></li><li class="dropdown-item"><!----> <a href="/blogs/categories/essay/" class="nav-link"><i class="iconfont undefined"></i>
  essay
</a></li><li class="dropdown-item"><!----> <a href="/blogs/categories/mlAndMath/" class="nav-link"><i class="iconfont undefined"></i>
  mlAndMath
</a></li><li class="dropdown-item"><!----> <a href="/blogs/categories/notes/" class="nav-link"><i class="iconfont undefined"></i>
  notes
</a></li></ul></div></div><div class="nav-item"><a href="/blogs/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/blogs/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/gq15760172077/blogs" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="mailto:1249224822@qq.com" class="nav-link external"><i class="iconfont reco-mail"></i>
  E-mail
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="http://wpa.qq.com/msgrd?v=3&amp;uin=1249224822&amp;site=qq&amp;menu=yes" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-qq"></i>
  qq
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-2d5f533b></div> <aside class="sidebar" data-v-2d5f533b><div class="personal-info-wrapper" data-v-ca798c94 data-v-2d5f533b><img src="/blogs/avatar.jpg" alt="author-avatar" class="personal-img" data-v-ca798c94> <h3 class="name" data-v-ca798c94>
    gouqi
  </h3> <div class="num" data-v-ca798c94><div data-v-ca798c94><h3 data-v-ca798c94>41</h3> <h6 data-v-ca798c94>Article</h6></div> <div data-v-ca798c94><h3 data-v-ca798c94>41</h3> <h6 data-v-ca798c94>Tag</h6></div></div> <hr data-v-ca798c94></div> <nav class="nav-links"><div class="nav-item"><a href="/blogs/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blogs/categories/algorithm/" class="nav-link"><i class="iconfont undefined"></i>
  algorithm
</a></li><li class="dropdown-item"><!----> <a href="/blogs/categories/essay/" class="nav-link"><i class="iconfont undefined"></i>
  essay
</a></li><li class="dropdown-item"><!----> <a href="/blogs/categories/mlAndMath/" class="nav-link"><i class="iconfont undefined"></i>
  mlAndMath
</a></li><li class="dropdown-item"><!----> <a href="/blogs/categories/notes/" class="nav-link"><i class="iconfont undefined"></i>
  notes
</a></li></ul></div></div><div class="nav-item"><a href="/blogs/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/blogs/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/gq15760172077/blogs" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="mailto:1249224822@qq.com" class="nav-link external"><i class="iconfont reco-mail"></i>
  E-mail
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="http://wpa.qq.com/msgrd?v=3&amp;uin=1249224822&amp;site=qq&amp;menu=yes" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-qq"></i>
  qq
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-64685f0e data-v-2d5f533b><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>HMM and CRF</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>gouqi</span>
            
          <span data-v-64685f0e>2020 - </span>
          2023
        </a></span></div></div> <div data-v-2d5f533b><main class="page"><div class="page-title" style="display:none;"><h1 class="title">HMM and CRF</h1> <div data-v-3b7f5bdf><i class="iconfont reco-account" data-v-3b7f5bdf><span data-v-3b7f5bdf>gouqi</span></i> <i class="iconfont reco-date" data-v-3b7f5bdf><span data-v-3b7f5bdf>2021-09-03</span></i> <i class="iconfont reco-eye" data-v-3b7f5bdf><span id="/blogs/blogs/mlAndMath/HMM&amp;&amp;CRF.html" data-flag-title="Your Article Title" class="leancloud-visitors" data-v-3b7f5bdf><a class="leancloud-visitors-count" style="font-size:.9rem;font-weight:normal;color:#999;"></a></span></i> <i class="iconfont reco-tag tags" data-v-3b7f5bdf><span class="tag-item" data-v-3b7f5bdf>ml</span></i></div></div> <div class="theme-reco-content content__default" style="display:none;"><h2 id="前言"><a href="#前言" class="header-anchor">#</a> 前言</h2> <p>  最近自学了一下HMM 和CRF，由于太菜了自己也不是很懂，但是还是记了一些笔记，怕以后搞忘了，就在这里记录下来。</p> <h2 id="hmm"><a href="#hmm" class="header-anchor">#</a> HMM</h2> <ul><li>初识HMM
<img src="/blogs/notes/HMM1.jpg" alt="HMM"><br> <img src="/blogs/notes/HMM2.jpg" alt="HMM"></li> <li>HMM 三个基本问题<br> <img src="/blogs/notes/HMM3.jpg" alt="HMM"><br> <img src="/blogs/notes/HMM4.jpg" alt="HMM"><br> <img src="/blogs/notes/HMM5.jpg" alt="HMM"></li> <li>HMM 相关博客<br> <a href="https://blog.csdn.net/xueyingxue001/article/details/52396494" target="_blank" rel="noopener noreferrer">hmm参考链接1<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><br> <a href="https://www.jianshu.com/p/c80ca0aa4213" target="_blank" rel="noopener noreferrer">hmm参考链接2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="crf"><a href="#crf" class="header-anchor">#</a> CRF</h2> <ul><li>初识CRF
<img src="/blogs/notes/CRF1.jpg" alt="CRF"><br> <img src="/blogs/notes/CRF2.jpg" alt="CRF"><br> <img src="/blogs/notes/CRF3.jpg" alt="CRF"><br> <img src="/blogs/notes/CRF4.jpg" alt="CRF"><br> <img src="/blogs/notes/CRF5.jpg" alt="CRF"><br> <img src="/blogs/notes/CRF6.jpg" alt="CRF"></li> <li>BiLstm 解析（注意求Z(x)的过程）<br> <a href="https://blog.csdn.net/xiaofalu/article/details/104277734" target="_blank" rel="noopener noreferrer">BiLstm参考链接<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>BiLstm源码</li></ul> <div class="language-python line-numbers-mode"><pre class="language-python"><code>   <span class="token keyword">import</span> torch
   <span class="token keyword">import</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">as</span> autograd
   <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
   <span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

   torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

   <span class="token comment">#  定义一些转换函数</span>
   <span class="token keyword">def</span> <span class="token function">argmax</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token comment"># return the argmax as a python int</span>
       _<span class="token punctuation">,</span> idx <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>vec<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
       <span class="token keyword">return</span> idx<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>


   <span class="token keyword">def</span> <span class="token function">prepare_sequence</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> to_ix<span class="token punctuation">)</span><span class="token punctuation">:</span>
       idxs <span class="token operator">=</span> <span class="token punctuation">[</span>to_ix<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> seq<span class="token punctuation">]</span>
       <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>idxs<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span> 


   <span class="token comment"># Compute log sum exp in a numerically stable way for the forward algorithm</span>
   <span class="token keyword">def</span> <span class="token function">log_sum_exp</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">:</span>
       max_score <span class="token operator">=</span> vec<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> argmax<span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">]</span>
       max_score_broadcast <span class="token operator">=</span> max_score<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> vec<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
       <span class="token keyword">return</span> max_score <span class="token operator">+</span> \
           torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>vec <span class="token operator">-</span> max_score_broadcast<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

   <span class="token keyword">import</span> pdb
   <span class="token keyword">class</span> <span class="token class-name">BiLSTM_CRF</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

       <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> tag_to_ix<span class="token punctuation">,</span> embedding<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token builtin">super</span><span class="token punctuation">(</span>BiLSTM_CRF<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
           self<span class="token punctuation">.</span>embedding_dim <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>embedding<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
           self<span class="token punctuation">.</span>hidden_dim <span class="token operator">=</span> hidden_dim
           self<span class="token punctuation">.</span>vocab_size <span class="token operator">=</span> vocab_size
           self<span class="token punctuation">.</span>tag_to_ix <span class="token operator">=</span> tag_to_ix
           self<span class="token punctuation">.</span>tagset_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tag_to_ix<span class="token punctuation">)</span>
           self<span class="token punctuation">.</span>word_embeds <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>embedding<span class="token punctuation">)</span>
           self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_dim<span class="token punctuation">,</span> hidden_dim <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span>
                               num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>batch_first <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

           <span class="token comment"># Maps the output of the LSTM into tag space.</span>
           self<span class="token punctuation">.</span>hidden2tag <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span>

           <span class="token comment"># Matrix of transition parameters.  Entry i,j is the score of</span>
           <span class="token comment"># transitioning *to* i *from* j.</span>
           self<span class="token punctuation">.</span>transitions <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>
               torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

           <span class="token comment"># These two statements enforce the constraint that we never transfer</span>
           <span class="token comment"># to the start tag and we never transfer from the stop tag</span>
           self<span class="token punctuation">.</span>transitions<span class="token punctuation">.</span>data<span class="token punctuation">[</span>tag_to_ix<span class="token punctuation">[</span>START_TAG<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000</span>   <span class="token comment"># 其它tag 到 START_TAG</span>
           self<span class="token punctuation">.</span>transitions<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> tag_to_ix<span class="token punctuation">[</span>STOP_TAG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000</span>    <span class="token comment"># STOP_TAG 到其它tag</span>

           self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>

       <span class="token keyword">def</span> <span class="token function">init_hidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token keyword">return</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

       <span class="token keyword">def</span> <span class="token function">_forward_alg</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feats<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token comment"># Do the forward algorithm to compute the partition function</span>
           init_alphas <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10000</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
           <span class="token comment"># START_TAG has all of the score.</span>
           init_alphas<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>START_TAG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span>

           <span class="token comment"># Wrap in a variable so that we will get automatic backprop</span>
           forward_var <span class="token operator">=</span> init_alphas

           <span class="token comment"># Iterate through the sentence</span>
           <span class="token keyword">for</span> feat <span class="token keyword">in</span> feats<span class="token punctuation">:</span>
               alphas_t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># The forward tensors at this timestep</span>
               <span class="token keyword">for</span> next_tag <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
                   <span class="token comment"># broadcast the emission score: it is the same regardless of</span>
                   <span class="token comment"># the previous tag</span>
                   emit_score <span class="token operator">=</span> feat<span class="token punctuation">[</span>next_tag<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>
                       <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span>
                   <span class="token comment"># the ith entry of trans_score is the score of transitioning to</span>
                   <span class="token comment"># next_tag from i</span>
                   trans_score <span class="token operator">=</span> self<span class="token punctuation">.</span>transitions<span class="token punctuation">[</span>next_tag<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
                   <span class="token comment"># The ith entry of next_tag_var is the value for the</span>
                   <span class="token comment"># edge (i -&gt; next_tag) before we do log-sum-exp</span>
                   next_tag_var <span class="token operator">=</span> forward_var <span class="token operator">+</span> trans_score <span class="token operator">+</span> emit_score
                   <span class="token comment"># The forward variable for this tag is log-sum-exp of all the</span>
                   <span class="token comment"># scores.</span>
                   alphas_t<span class="token punctuation">.</span>append<span class="token punctuation">(</span>log_sum_exp<span class="token punctuation">(</span>next_tag_var<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
               forward_var <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>alphas_t<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
           terminal_var <span class="token operator">=</span> forward_var <span class="token operator">+</span> self<span class="token punctuation">.</span>transitions<span class="token punctuation">[</span>self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>STOP_TAG<span class="token punctuation">]</span><span class="token punctuation">]</span>
           alpha <span class="token operator">=</span> log_sum_exp<span class="token punctuation">(</span>terminal_var<span class="token punctuation">)</span>
           <span class="token keyword">return</span> alpha

       <span class="token keyword">def</span> <span class="token function">_get_lstm_features</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>
           self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
           embeds <span class="token operator">=</span> self<span class="token punctuation">.</span>word_embeds<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
           lstm_out<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>embeds<span class="token punctuation">)</span>
           lstm_feats <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden2tag<span class="token punctuation">(</span>lstm_out<span class="token punctuation">)</span>
           <span class="token keyword">return</span> lstm_feats

       <span class="token keyword">def</span> <span class="token function">_score_sentence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feats<span class="token punctuation">,</span> tags<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token comment"># Gives the score of a provided tag sequence</span>
           score <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
           tags <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>START_TAG<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tags<span class="token punctuation">]</span><span class="token punctuation">)</span>
           <span class="token keyword">for</span> i<span class="token punctuation">,</span> feat <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>feats<span class="token punctuation">)</span><span class="token punctuation">:</span>
               score <span class="token operator">=</span> score <span class="token operator">+</span> \
                   self<span class="token punctuation">.</span>transitions<span class="token punctuation">[</span>tags<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tags<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+</span> feat<span class="token punctuation">[</span>tags<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
           score <span class="token operator">=</span> score <span class="token operator">+</span> self<span class="token punctuation">.</span>transitions<span class="token punctuation">[</span>self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>STOP_TAG<span class="token punctuation">]</span><span class="token punctuation">,</span> tags<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
           <span class="token keyword">return</span> score

       <span class="token keyword">def</span> <span class="token function">_viterbi_decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feats<span class="token punctuation">)</span><span class="token punctuation">:</span>
           backpointers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

           <span class="token comment"># Initialize the viterbi variables in log space</span>
           init_vvars <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10000</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
           init_vvars<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>START_TAG<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>

           <span class="token comment"># forward_var at step i holds the viterbi variables for step i-1</span>
           forward_var <span class="token operator">=</span> init_vvars
           <span class="token keyword">for</span> feat <span class="token keyword">in</span> feats<span class="token punctuation">:</span>
               bptrs_t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># holds the backpointers for this step</span>
               viterbivars_t <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># holds the viterbi variables for this step</span>

               <span class="token keyword">for</span> next_tag <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>tagset_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
                   <span class="token comment"># next_tag_var[i] holds the viterbi variable for tag i at the</span>
                   <span class="token comment"># previous step, plus the score of transitioning</span>
                   <span class="token comment"># from tag i to next_tag.</span>
                   <span class="token comment"># We don't include the emission scores here because the max</span>
                   <span class="token comment"># does not depend on them (we add them in below)</span>
                   next_tag_var <span class="token operator">=</span> forward_var <span class="token operator">+</span> self<span class="token punctuation">.</span>transitions<span class="token punctuation">[</span>next_tag<span class="token punctuation">]</span>
                   best_tag_id <span class="token operator">=</span> argmax<span class="token punctuation">(</span>next_tag_var<span class="token punctuation">)</span>
                   bptrs_t<span class="token punctuation">.</span>append<span class="token punctuation">(</span>best_tag_id<span class="token punctuation">)</span>
                   viterbivars_t<span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_tag_var<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>best_tag_id<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
               <span class="token comment"># Now add in the emission scores, and assign forward_var to the set</span>
               <span class="token comment"># of viterbi variables we just computed</span>
               forward_var <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>viterbivars_t<span class="token punctuation">)</span> <span class="token operator">+</span> feat<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
               backpointers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>bptrs_t<span class="token punctuation">)</span>

           <span class="token comment"># Transition to STOP_TAG</span>
           terminal_var <span class="token operator">=</span> forward_var <span class="token operator">+</span> self<span class="token punctuation">.</span>transitions<span class="token punctuation">[</span>self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>STOP_TAG<span class="token punctuation">]</span><span class="token punctuation">]</span>
           best_tag_id <span class="token operator">=</span> argmax<span class="token punctuation">(</span>terminal_var<span class="token punctuation">)</span>
           path_score <span class="token operator">=</span> terminal_var<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>best_tag_id<span class="token punctuation">]</span>

           <span class="token comment"># Follow the back pointers to decode the best path.</span>
           best_path <span class="token operator">=</span> <span class="token punctuation">[</span>best_tag_id<span class="token punctuation">]</span>
           <span class="token keyword">for</span> bptrs_t <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span>backpointers<span class="token punctuation">)</span><span class="token punctuation">:</span>
               best_tag_id <span class="token operator">=</span> bptrs_t<span class="token punctuation">[</span>best_tag_id<span class="token punctuation">]</span>
               best_path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>best_tag_id<span class="token punctuation">)</span>
           <span class="token comment"># Pop off the start tag (we dont want to return that to the caller)</span>
           start <span class="token operator">=</span> best_path<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
           <span class="token keyword">assert</span> start <span class="token operator">==</span> self<span class="token punctuation">.</span>tag_to_ix<span class="token punctuation">[</span>START_TAG<span class="token punctuation">]</span>  <span class="token comment"># Sanity check</span>
           best_path<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>
           <span class="token keyword">return</span> path_score<span class="token punctuation">,</span> best_path

       <span class="token keyword">def</span> <span class="token function">neg_log_likelihood</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs_ids<span class="token punctuation">,</span>label<span class="token punctuation">,</span>text_lengths<span class="token punctuation">,</span>mask<span class="token punctuation">)</span><span class="token punctuation">:</span>
           batch_feats <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_lstm_features<span class="token punctuation">(</span>inputs_ids<span class="token punctuation">)</span>
           total_score <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
           batch_size <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>inputs_ids<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
           <span class="token keyword">for</span> feats<span class="token punctuation">,</span>lab<span class="token punctuation">,</span>text_len <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>batch_feats<span class="token punctuation">,</span>label<span class="token punctuation">,</span>text_lengths<span class="token punctuation">)</span><span class="token punctuation">:</span>
               feats <span class="token operator">=</span> feats<span class="token punctuation">[</span><span class="token punctuation">:</span>text_len<span class="token punctuation">]</span>
               tags <span class="token operator">=</span> lab<span class="token punctuation">[</span><span class="token punctuation">:</span>text_len<span class="token punctuation">]</span>
               forward_score <span class="token operator">=</span> self<span class="token punctuation">.</span>_forward_alg<span class="token punctuation">(</span>feats<span class="token punctuation">)</span>
               gold_score <span class="token operator">=</span> self<span class="token punctuation">.</span>_score_sentence<span class="token punctuation">(</span>feats<span class="token punctuation">,</span> tags<span class="token punctuation">)</span>
               total_score <span class="token operator">+=</span> forward_score <span class="token operator">-</span> gold_score
           <span class="token keyword">return</span> total_score <span class="token operator">/</span> batch_size

       <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs_ids<span class="token punctuation">,</span>label<span class="token punctuation">,</span>text_lengths<span class="token punctuation">,</span>mask<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># dont confuse this with _forward_alg above.</span>
           <span class="token comment"># Get the emission scores from the BiLSTM</span>
           batch_feats <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_lstm_features<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>
           batch_score <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
           batch_tags <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
           <span class="token keyword">for</span> feats<span class="token punctuation">,</span>text_len <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>batch_feats<span class="token punctuation">,</span>text_lengths<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token comment"># Find the best path, given the features.</span>
               feats <span class="token operator">=</span> feats<span class="token punctuation">[</span><span class="token punctuation">:</span>text_len<span class="token punctuation">]</span>
               score<span class="token punctuation">,</span> tag_seq <span class="token operator">=</span> self<span class="token punctuation">.</span>_viterbi_decode<span class="token punctuation">(</span>feats<span class="token punctuation">)</span>
               batch_score <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_score<span class="token punctuation">,</span>score<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
               batch_tags<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tag_seq<span class="token punctuation">)</span>
           <span class="token keyword">return</span> batch_score<span class="token punctuation">,</span> batch_tags
<span class="token comment">## 训练部分，具体需要自己修改一下，此处只是放了之前的项目代码片段</span>
global_step <span class="token operator">=</span> <span class="token number">0</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span> <span class="token comment"># </span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
       input_ids<span class="token punctuation">,</span>label<span class="token punctuation">,</span>text_lengths<span class="token punctuation">,</span>mask <span class="token operator">=</span> batch
       optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
       loss <span class="token operator">=</span> model<span class="token punctuation">.</span>neg_log_likelihood<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span>label<span class="token punctuation">,</span>text_lengths<span class="token punctuation">,</span>mask<span class="token punctuation">)</span>
       <span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
       loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
       optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
       scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
       global_step <span class="token operator">+=</span> <span class="token number">1</span>
       <span class="token keyword">if</span> global_step <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">and</span> global_step <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
           <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch:%d,global_step: %d, loss:%.5f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>global_step<span class="token punctuation">,</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
           batch_score<span class="token punctuation">,</span>batch_tags <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span>label<span class="token punctuation">,</span>text_lengths<span class="token punctuation">,</span>mask<span class="token punctuation">)</span>
           <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'orgin-tag:'</span><span class="token punctuation">,</span>label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>text_lengths<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
           <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'predict-tag:'</span><span class="token punctuation">,</span>batch_tags<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br><span class="line-number">128</span><br><span class="line-number">129</span><br><span class="line-number">130</span><br><span class="line-number">131</span><br><span class="line-number">132</span><br><span class="line-number">133</span><br><span class="line-number">134</span><br><span class="line-number">135</span><br><span class="line-number">136</span><br><span class="line-number">137</span><br><span class="line-number">138</span><br><span class="line-number">139</span><br><span class="line-number">140</span><br><span class="line-number">141</span><br><span class="line-number">142</span><br><span class="line-number">143</span><br><span class="line-number">144</span><br><span class="line-number">145</span><br><span class="line-number">146</span><br><span class="line-number">147</span><br><span class="line-number">148</span><br><span class="line-number">149</span><br><span class="line-number">150</span><br><span class="line-number">151</span><br><span class="line-number">152</span><br><span class="line-number">153</span><br><span class="line-number">154</span><br><span class="line-number">155</span><br><span class="line-number">156</span><br><span class="line-number">157</span><br><span class="line-number">158</span><br><span class="line-number">159</span><br><span class="line-number">160</span><br><span class="line-number">161</span><br><span class="line-number">162</span><br><span class="line-number">163</span><br><span class="line-number">164</span><br><span class="line-number">165</span><br><span class="line-number">166</span><br><span class="line-number">167</span><br><span class="line-number">168</span><br><span class="line-number">169</span><br><span class="line-number">170</span><br><span class="line-number">171</span><br><span class="line-number">172</span><br><span class="line-number">173</span><br><span class="line-number">174</span><br><span class="line-number">175</span><br><span class="line-number">176</span><br><span class="line-number">177</span><br><span class="line-number">178</span><br><span class="line-number">179</span><br><span class="line-number">180</span><br><span class="line-number">181</span><br><span class="line-number">182</span><br><span class="line-number">183</span><br><span class="line-number">184</span><br><span class="line-number">185</span><br><span class="line-number">186</span><br><span class="line-number">187</span><br><span class="line-number">188</span><br><span class="line-number">189</span><br><span class="line-number">190</span><br><span class="line-number">191</span><br><span class="line-number">192</span><br><span class="line-number">193</span><br><span class="line-number">194</span><br><span class="line-number">195</span><br><span class="line-number">196</span><br></div></div></div> <footer class="page-edit" style="display:none;"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">3/24/2023, 6:36:39 AM</span></div></footer> <!----> <!----> <!----></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/blogs/assets/js/app.3f11a259.js" defer></script><script src="/blogs/assets/js/3.20f81737.js" defer></script><script src="/blogs/assets/js/1.0bcafa9d.js" defer></script><script src="/blogs/assets/js/36.88d814f7.js" defer></script>
  </body>
</html>
